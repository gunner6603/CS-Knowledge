# 운영체제
## 운영체제 기본 개념
* 시스템 자원 (또는 자원) : 프로그램 실행에 마땅히 필요한 요소
* 운영체제 : 실행할 프로그램에 필요한 자원을 할당하고, 프로그램이 올바르게 실행되도록 돕는 특별한 프로그램
* 운영체제는 메모리 내 '커널 영역'이라는 공간에 따로 적재되어 실행됨
* 사용자 영역 : 커널 영역을 제외한 나머지 영역, 사용자가 이용하는 응용 프로그램이 적재되는 영역
* 운영체제는 커널 영역에 적재되어 사용자 영역에 적재된 프로그램들에 자원을 할당하고 이들이 올바르게 실행되도록 도움
* 커널 : 운영체제의 핵심부, 운영체제의 핵심 서비스를 담당하는 부분
    * 운영체제 서비스 : 운영체제가 응용 프로그램에 제공하는 기능들
    * 자원에 접근하고 조작하는 기능, 프로그램이 올바르고 안전하게 실행되게 하는 기능 등이 운영체제의 핵심 서비스에 속함
* 사용자 인터페이스 : 사용자가 컴퓨터와 상호작용하는 통로
    * 커널에 포함되지 않는 서비스
    * GUI, CLI로 분류
* 응용 프로그램은 하드웨어 자원에 직접 접근하는 것이 불가능하고, 응용 프로그램의 요청을 받은 운영체제가 대신 자원에 접근하여 요청한 작업을 수행함
    * 이를 이중 모드로 구현
* 이중 모드 : CPU가 명령어를 실행하는 모드를 사용자 모드와 커널 모드로 구분하는 방식
    * 사용자 모드 : 운영체제 서비스를 제공받을 수 없는 실행 모드, 커널 영역의 코드를 실행할 수 없는 모드
        * 일반적인 응용 프로그램은 기본적으로 사용자 모드로 실행됨
        * 사용자 모드로 실행 중인 CPU는 하드웨어 자원에 접근하는 명령어를 실행할 수 없음
    * 커널 모드 : 운영체제 서비스를 제공받을 수 있는 실행 모드, 커널 영역의 코드를 실행할 수 있는 모드
* 시스템 호출 : 운영체제 서비스를 제공받기 위해 커널 모드로 전환하는 방법
    * 시스템 호출은 소프트웨어 인터럽트
    * 소프트웨어 인터럽트 : 특정 명령어에 의해 발생하는 인터럽트
    * 처리 순서
        1. 시스템 호출을 발생시키는 명령어 실행
        2. CPU는 작업을 백업하고, 커널 모드로 전환
        3. 시스템 호출을 수행하는 코드(인터럽트 서비스 루틴, 운영체제 코드)를 실행
        4. 사용자 모드로 복귀하여 기존에 실행하던 프로그램을 이어서 실행
* 운영체제의 핵심 서비스
    * 프로세스 관리
        * 프로세스를 메모리에 적재, 삭제
        * 다양한 프로세스를 관리하고 실행
    * 자원 접근 및 할당
        * 운영체제는 프로세스들이 사용할 자원에 (대신) 접근하고 조작 -> 프로세스는 운영체제를 통해 자원을 이용할 수 있음
        * CPU : 여러 프로세스가 CPU를 이용하므로 CPU 스케줄링 필요
        * 메모리 : 프로세스에 메모리 할당
        * 입출력장치 : 인터럽트 서비스 루틴 제공 (커널 영역에 있음)
    * 파일 시스템 관리


## 프로세스와 스레드
### 프로세스 개요
* 프로세스 : 실행 중인 프로그램
    * 포그라운드 프로세스
    * 백그라운드 프로세스
        * 데몬\[Unix\](서비스\[Window\]) : 사용자와 상호작용하지 않는 백그라운드 프로세스
* 운영체제는 빠르게 번갈아 수행되는 프로세스의 실행 순서를 관리하고, 프로세스에 CPU를 비롯한 자원을 배분 -> 이를 위해 프로세스 제어 블록 이용
* 프로세스 제어 블록 (PCB; Process Control Block)
    * 프로세스와 관련된 정보를 제공하는 자료구조
    * 프로세스 식별 정보, 프로세스 처리에 필요한 정보가 저장됨
    * 프로세스 생성 시 커널 영역에 생성되고 실행이 끝나면 폐기됨
    * PCB에 담기는 정보
        1. 프로세스 ID(PID)
            * 특정 프로세스를 식별하기 위해 부여하는 고유한 번호
        2. 레지스터 값
            * 해당 프로세스가 실행하며 사용했던 레지스터 값
            * 차례가 돌아왔을 때 작업을 이어 실행하기 위해 필요
        3. 프로세스 상태
            * 입출력장치를 사용하기 위해 기다리는 상태, CPU를 이용하고 있는 상태 등
        4. CPU 스케줄링 정보
            * 프로세스가 언제, 어떤 순서로 CPU를 할당받을지에 대한 정보
        5. 메모리 관리 정보
            * 프로세스가 메모리 어느 곳에 저장되어 있는지에 대한 정보
            * 베이스 레지스터, 한계 레지스터 값, 페이지 테이블 정보
        6. 사용한 파일과 입출력장치 목록
* 문맥 : 하나의 프로세스 수행을 재개하기 위해 기억해야 할 (중간) 정보
    * 프로세스의 문맥은 해당 프로세스의 PCB에 기록되어 있음
    * 프로세스가 CPU를 사용할 수 있는 시간이 끝나거나 인터럽트가 발생하면 운영체제는 해당 프로세스의 PCB에 문맥을 백업
* 문맥 교환 : 기존 프로세스의 문맥을 PCB에 백업하고, 문맥을 PCB로부터 복구하여 새로운 프로세스를 실행하는 것
    * 여러 프로세스가 끊임없이 빠르게 번갈아 가며 실행되는 원리
    * 문맥 교환이 너무 자주 일어나면 오버헤드가 발생할 수 있음
    * 오버헤드 : 어떤 처리를 하기 위해 들어가는 간접적인 처리 시간, 메모리
* 프로세스의 메모리 영역
    * 하나의 프로세스는 사용자 영역에 크게 코드 영역, 데이터 영역, 힙 영역, 스택 영역으로 나뉘어 저장
    * 코드 영역 : CPU가 실행할, 기계어로 이루어진 명령어가 저장되는 공간
        * 읽기 전용 공간
    * 데이터 영역 : 프로그램이 실행되는 내내 유지할 데이터가 저장되는 공간
        * 전역 변수, 정적(static) 필드 등
    * 힙 영역 : 프로그래머가 직접 할당할 수 있는 저장 공간
        * 힙 영역의 메모리 공간을 할당했다면 언젠가는 해당 공간을 반환해야 함 -> 그렇지 않으면 메모리 누수가 발생함
    * 스택 영역 : 데이터를 일시적으로 저장하는 공간
        * 일시적으로 저장되는 데이터에는 매개 변수, 지역 변수 등이 있음
    * 코드 영역과 데이터 영역은 프로세스 실행 과정에서 크기가 고정되므로 정적 할당 영역이라고 부름
    * 힙 영역과 스택 영역은 프로세스 실행 과정에서 크기가 변할 수 있으므로 동적 할당 영역이라고 부름


### 프로세스 상태와 계층 구조
* 프로세스 상태
    1. 생성 상태(new) : 막 메모리에 적재되어 PCB를 할당받은 상태
    2. 준비 상태(ready) : 실행할 준비가 완료되어 CPU 할당을 기다리고 있는 상태
        * 준비 상태인 프로세스가 실행 상태로 전환되는 것을 디스패치라고 함
    3. 실행 상태(running) : CPU를 할당받아 실행 중인 상태
        * 할당된 시간을 모두 사용하면 다시 준비 상태가 됨
        * 입출력장치를 사용하면 입출력 작업이 끝날 때까지 대기 상태가 됨
    4. 대기 상태(blocked) : 입출력장치의 작업을 기다리는 상태
        * 입출력 작업이 완료되면 다시 준비 상태가 됨
    5. 종료 상태(terminated) : 프로세스가 종료된 상태
        * 프로세스가 종료되면 운영체제는 PCB와 프로세스가 사용한 메모리를 정리함
    * 운영체제는 프로세스 상태를 PCB에 기록하며 프로세스들을 관리함
* 프로세스는 실행 도중 시스템 호출을 통해 다른 프로세스를 생성할 수 있음
    * 부모 프로세스 : 새 프로세스를 생성한 프로세스
    * 자식 프로세스 : 부모 프로세스에 의해 생성된 프로세스
* 프로세스 계층 구조 : 프로세스가 프로세스를 낳는 계층적인 구조 (트리 구조)
* 프로세스 생성 기법
    * 부모 프로세스는 fork 시스템 호출을 통해 자신의 복사본을 자식 프로세스로 생성함
        * 자식 프로세스는 부모 프로세스의 복사본이므로 부모 프로세스의 자원들(메모리 내의 내용, 열린 파일의 목록 등)을 상속함
    * fork를 통해 생성된 자식 프로세스는 exec 시스템 호출을 통해 새로운 프로그램 내용으로 전환되어 실행됨
        * 자식 프로세스의 코드 영역과 데이터 영역의 내용이 새로 실행할 프로그램의 내용으로 바뀌고, 나머지 영역은 초기화됨
    * 여러 프로세스가 계층적으로 실행되는 과정은 fork와 exec 시스템 호출의 반복임


### 스레드
* 스레드 : 프로세스 내의 실행 흐름 단위
    * 하나의 프로세스는 여러 개의 스레드를 가질 수 있음
    * 단일 스레드 프로세스 : 하나의 실행 흐름을 가지고 한 번에 한 부분만 실행되는 프로세스
    * 멀티 스레드 프로세스 : 프로세스를 구성하는 여러 명령어를 동시에 실행 가능
    * 스레드는 프로세스 내에서 각기 다른 스레드 ID, 프로그램 카운터 값을 비롯한 레지스터 값, 스택을 가짐
    * 프로세스의 스레드들은 실행에 필요한 최소한의 정보만을 유지한 채 프로세스 자원을 공유하며 실행됨
    * 많은 운영체제는 CPU에 처리할 작업을 전달할 때 스레드 단위로 전달
* 멀티프로세스 : 여러 프로세스를 동시에 실행하는 것
* 멀티스레드 : 여러 스레드로 하나의 프로세스를 동시에 실행하는 것
* 같은 프로세스 내의 모든 스레드는 동일한 주소 공간의 코드, 데이터, 힙 영역을 공유하고, 열린 파일과 같은 프로세스 자원을 공유
    * 여러 프로세스를 병행 실행하는 것보다 메모리를 더 효율적으로 사용
    * 스레드 간 협력과 통신에 유리
    * 그러나 하나의 스레드에 문제가 생기면 프로세스 전체에 문제가 생길 수 있음
* 프로세스 간 통신(IPC; Inter-Process Communication) : 프로세스 간 자원을 공유하고 데이터를 주고받는 것
    * 파일, 공유 메모리 등을 통해 가능


## CPU 스케줄링
### CPU 스케줄링 개요
* CPU 스케줄링 : 운영체제가 프로세스들에게 CPU 자원을 배분하는 방법
* 프로세스 우선순위 : 프로세스의 중요도에 맞게 프로세스가 CPU를 이용할 수 있도록 하기 위해 운영체제는 프로세스마다 우선순위를 부여
    * 운영체제는 각 프로세스의 PCB에 우선순위를 명시하고, PCB에 적힌 우선순위를 기준으로 먼저 처리할 프로세스를 결정함
    * 우선순위가 높은 프로세스는 더 빨리, 더 자주 실행됨
    * 입출력 작업이 많은 프로세스는 우선순위가 높음
        * 대부분의 프로세스는 CPU와 입출력장치를 모두 사용하며 실행되므로 실행 상태와 대기 상태를 반복하며 실행됨
        * 입출력 집중 프로세스 : 입출력 작업이 많은 프로세스, 대기 상태에 더 많이 머무름, 입출력 버스트(입출력장치를 기다리는 작업)가 많은 프로세스
        * CPU 집중 프로세스 : CPU 작업이 많은 프로세스, 실행 상태에 더 많이 머무름, CPU 버스트(CPU를 이용하는 작업)가 많은 프로세스
        * 입출력 집중 프로세스를 먼저 실행시켜 대기 상태로 만들고, CPU 집중 프로세스에 집중적으로 CPU를 할당하는 것이 효율적임
* 스케줄링 큐
    * 특정 자원을 이용할 프로세스들은 스케줄링 큐에 삽입되어 차례를 기다림 (실제 삽입되는 것은 PCB)
    * 준비 큐 : CPU를 이용할 프로세스들이 삽입되는 큐
        * 운영체제는 PCB들을 준비 큐에 삽입된 순서대로 하나씩 꺼내어 프로세스를 실행하되, 우선순위가 높은 프로세스를 먼저 실행
    * 대기 큐 : 입출력장치를 이용할 프로세스들이 삽입되는 큐
        * 입출력 작업을 요청한 프로세스는 대기 큐에서 작업이 완료되기를 기다림
        * 입출력 완료 인터럽트(하드웨어 인터럽트)가 발생하면 운영체제는 대기 큐에서 작업이 완료된 PCB를 찾고, 이 PCB를 준비 상태로 변경한 뒤 대기 큐에서 제거, 준비 큐에 삽입함
* 선점형 스케줄링 : 프로세스가 자원을 사용하고 있더라도 운영체제가 프로세스로부터 자원을 강제로 빼앗아 다른 프로세스에 할당할 수 있는 스케줄링 방식
    * 어느 하나의 프로세스가 자원 사용을 독점할 수 없는 스케줄링 방식
    * 현재 대부분의 운영체제가 차용하는 방식
* 비선점형 스케줄링 : 하나의 프로세스가 자원을 사용하고 있다면 그 프로세스가 종료되거나 스스로 대기 상태에 접어들기 전까지 다른 프로세스가 끼어들 수 없는 스케줄링
    * 하나의 프로세스가 자원 사용을 독점할 수 있는 스케줄링 방식
* 선점형 스케줄링은 한 프로세스의 자원 독점을 막고 프로세스들에 골고루 자원을 배분할 수 있다는 장점이 있으나, 문맥 교환 과정에서 오버헤드가 발생할 수 있음
* 비선점형 스케줄링은 문맥 교환에서 발생하는 오버헤드가 적지만, 하나의 프로세스가 자원을 사용 중이라면 당장 자원을 사용해야 하는 상황에서도 무작정 기다려야 하고, 모든 프로세스가 골고루 자원을 사용할 수 없음


### CPU 스케줄링 알고리즘
1. 선입 선처리 스케줄링
    * FCFS 스케줄링
    * 준비 큐에 삽입된 순서대로 프로세스들을 처리하는 비선점형 스케줄링 방식
    * 때때로 프로세스들이 기다리는 시간이 매우 길어질 수 있음 -> 호위 효과
    * 호위 효과(convoy effect) : 준비 큐에 먼저 삽입된 프로세스의 CPU 버스트 시간이 길면 뒤에 삽입된 프로세스들은 긴 시간을 기다려야 함
2. 최단 작업 우선 스케줄링
    * SJF 스케줄링
    * 준비 큐에 삽입된 프로세스들 중 CPU 이용 시간이 가장 짧은 프로세스부터 실행하는 스케줄링 방식
    * 기본적으로 비선점형 스케줄링 방식으로 분류됨
3. 라운드 로빈 스케줄링
    * 선입 선처리 스케줄링에 타임 슬라이스 개념이 더해진 선점형 스케줄링
    * 타임 슬라이스 : 각 프로세스가 CPU를 사용할 수 있는 정해진 시간
    * 정해진 시간 내에 프로세스가 완료되지 않으면 다시 준비 큐의 맨 뒤에 삽입
    * 타임 슬라이스 크기가 중요
        * 타임 슬라이스가 지나치게 크면 사실상 선입 선처리 스케줄링과 다를 바 없어 호위 효과가 생길 여지가 있음
        * 타임 슬라이스가 지나치게 작으면 문맥 교환에서 오버헤드 발생
4. 최소 잔여 시간 우선 스케줄링
    * SRT 스케줄링
    * 선점형 최단 작업 우선 스케줄링
    * 프로세스가 준비 큐에 삽입될 때마다 남은 작업 시간이 가장 적은 프로세스를 선택하여 실행 (선점형)
5. 우선순위 스케줄링
    * 프로세스들에 우선순위를 부여하고, 가장 높은 우선순위를 가진 프로세스부터 실행하는 스케줄링 알고리즘
    * 우선순위가 같은 프로세스들은 선입 선처리로 스케줄링됨
    * 기아 현상 유발
        * 기아 현상 : 준비 큐에 먼저 삽입되었음에도 불구하고 우선순위가 낮은 프로세스의 실행이 우선순위가 높은 프로세스에 의해 계속 연기되는 현상
        * 이를 해결하기 위해 에이징 기법 도입
        * 에이징 : 대기 중인 프로세스의 우선순위를 점차 증가시키는 방법
6. 다단계 큐 스케줄링
    * 우선순위 스케줄링의 발전된 형태
    * 우선순위별로 준비 큐를 여러 개 사용하는 스케줄링 방식
    * 우선순위가 가장 높은 큐에 있는 프로세스들을 먼저 처리하고, 그 큐가 비어 있으면 그 다음 우선순위 큐에 있는 프로세스들을 처리
7. 다단계 피드백 큐 스케줄링
    * 다단계 큐 스케줄링의 발전된 형태
    * 다단계 큐 스케줄링에서는 프로세스들이 큐 사이를 이동할 수 없으므로 기아 현상 발생 -> 이를 보완
    * 프로세스들이 큐 사이를 이동 가능
    * 새로 준비 상태가 된 프로세스는 가장 높은 우선순위 큐에 삽입되고 일정 시간(타임 슬라이스) 동안 실행됨
    * 해당 큐에서 실행이 끝나지 않으면 다음 우선순위 큐에 삽입되어 실행됨
        * CPU 집중 프로세스들은 CPU를 비교적 오래 사용하므로 자연스레 우선순위가 낮아짐
        * 입출력 집중 프로세스들은 CPU를 비교적 적게 사용하므로 우선순위가 높은 큐에서 실행 완료됨
    * 낮은 우선순위 큐에서 기다리고 있는 프로세스는 점차 우선순위가 높은 큐로 이동 (에이징 기법) -> 기아 현상 예방
    * 구현이 복잡하지만 가장 일반적인 CPU 스케줄링 알고리즘


## 동기화
### 동기화 개요
* 프로세스 동기화 : 동시에 실행되는 프로세스들 사이에 수행 시기를 맞추는 것
    * 실행 순서 제어를 위한 동기화 : 프로세스를 올바른 순서대로 실행하기
    * 상호 배제를 위한 동기화 : 동시에 접근해서는 안 되는 자원에 하나의 프로세스만 접근하게 하기
    * 스레드도 동기화 대상 (실행의 흐름을 갖는 모든 것은 동기화 대상)
* 공유 자원 : 공동으로 사용하는 자원
    * 전역 변수, 파일, 입출력장치, 보조기억장치 등
* 임계 구역 : 공유 자원에 접근하는 코드 중 동시에 실행하면 문제가 발생하는 코드 영역
    * 임계 구역에 진입한 프로세스가 있다면 다른 프로세스는 임계 구역 밖에서 기다려야 함
* 레이스 컨디션 : 잘못된 실행으로 인해 여러 프로세스가 동시에 임계 구역의 코드를 실행하여 문제가 발생하는 경우
    * 레이스 컨디션이 발생하면 자원(데이터)의 일관성이 깨짐
* 상호 배제를 위한 동기화 : 레이스 컨디션이 발생하지 않도록 두 개 이상의 프로세스가 임계 구역에 동시에 접근하지 못하도록 관리하는 것
    * 이를 위해 세 가지 원칙이 지켜져야 함
        1. 상호 배제 : 한 프로세스가 임계 구역에 진입했다면 다른 프로세스는 임계 구역에 들어올 수 없음
        2. 진행 : 임계 구역에 어떤 프로세스도 진입하지 않았다면 임계 구역에 진입하고자 하는 프로세스는 들어갈 수 있어야 함
        3. 유한 대기 : 한 프로세스가 임계 구역에 진입하고 싶다면 그 프로세스는 언젠가는 임계 구역에 들어올 수 있어야 함(임계 구역에 들어오기 위해 무한정 대기해서는 안 됨)


### 동기화 기법
* 뮤텍스 락(Mutex lock; MUTual EXclusion lock)
    * 상호 배제를 위한 동기화 도구
    * 매우 단순한 형태의 뮤텍스 락은 다음과 같이 구성
        * 자물쇠 역할 : 프로세스들이 공유하는 전역 변수 lock
        * 임계 구역을 잠그는 역할 : acquire 함수
        * 임계 구역의 잠금을 해제하는 역할 : release 함수
        * 임계 구역 진입 전후로 acquire 함수와 release 함수 호출
    * 프로세스는 락을 획득할 수 없다면 무작정 기다리고, 락을 획득할 수 있다면 임계 구역을 잠근 뒤 임계 구역에서의 작업을 진행하고, 임계 구역에서 빠져나올 때엔 다시 임계 구역의 잠금을 해제함으로써 임계 구역을 보호함
    * 임계 구역이 잠겨 있을 경우 프로세스는 반복적으로 lock을 확인함 -> 바쁜 대기
* 세마포(semaphore)
    * 공유 자원이 여러 개 있는 상황에서 적용 가능한 동기화 도구
    * 뮤텍스 락과 비슷하게 하나의 변수와 두 개의 함수로 단순하게 구현 가능
        * 임계 구역에 진입할 수 있는 프로세스의 개수(사용 가능한 공유 자원의 개수)를 나타내는 전역 변수 S
        * 임계 구역에 들어가도 좋은지, 기다려야 할지를 알려주는 wait 함수
        * 임계 구역 앞에서 기다리는 프로세스에 진입 신호를 주는 signal 함수
        * 임계 구역 진입 전후로 wait 함수와 signal 함수 호출
    * 바쁜 대기 문제가 발생 -> CPU 주기를 낭비 -> 세마포를 위한 대기 큐를 이용하여 문제 해결
        * wait 함수는 사용할 수 있는 자원이 없을 경우 해당 프로세스 상태를 대기 상태로 만들고, PCB를 세마포를 위한 대기 큐에 삽입
        * 다른 프로세스가 임계 구역에서의 작업이 끝나고 signal 함수를 호출하면 signal 함수는 대기 중인 프로세스를 대기 큐에서 제거하고, 프로세스 상태를 준비 상태로 변경한 뒤 준비 큐로 옮겨 줌 -> 임계 구역 진입
    * 실행 순서 제어를 위한 동기화에도 사용 가능
        * 세마포의 변수 S를 0으로 설정하고 먼저 실행할 프로세스 뒤에 signal 함수, 다음에 실행할 프로세스 앞에 wait 함수를 붙임
* 모니터(monitor)
    * 공유 자원과 공유 자원에 접근하기 위한 인터페이스를 묶어 관리
    * 모니터에 진입하기 위한 큐를 만들고, 모니터 안에 항상 하나의 프로세스만 들어오도록 하여 상호 배제를 위한 동기화를 제공
    * 조건 변수를 사용하여 실행 순서 제어를 위한 동기화를 제공
        * 조건 변수로 wait, signal 연산을 수행할 수 있음 ex) x.wait(), y.signal()
            * wait는 호출한 프로세스의 상태를 대기 상태로 전환하고 일시적으로 조건 변수에 대한 대기 큐에 삽입하는 연산
            * signal은 wait를 호출하여 큐에 삽입된 프로세스의 실행을 재개하는 연산
        * 특정 프로세스가 아직 실행할 조건이 되지 않았을 때는 wait를 통해 실행을 중단
        * 특정 프로세스가 실행될 조건이 충족되었을 때에는 signal을 통해 실행을 재개


## 교착 상태
### 교착 상태 개요
* 교착 상태 : 일어나지 않을 사건을 기다리며 무한히 대기하는 현상
* 식사하는 철학자 문제
    * 교착 상태의 발생을 보여주는 예시
    * 철학자 : 프로세스 혹은 스레드
    * 포크 : 자원 혹은 임계 구역
    * 생각하는 행위 : 자원을 기다리는 것
* 자원 할당 그래프 : 어떤 프로세스가 어떤 자원을 사용하고 있고, 어떤 프로세스가 어떤 자원을 기다리고 있는지 표현하는 간단한 그래프
    * 그래프는 다음과 같은 규칙으로 그려짐
        1. 프로세스는 원으로, 자원의 '종류'는 사각형으로 표현
        2. 사용할 수 있는 자원의 개수는 자원 사각형 내에 점으로 표현
        3. 프로세스가 어떤 자원을 할당받아 사용 중이라면 자원에서 프로세스를 향해 화살표를 표시
        4. 프로세스가 어떤 자원을 기다리고 있다면 프로세스에서 자원으로 화살표를 표시
    * 교착 상태가 발생한 상황에서는 자원 할당 그래프가 사이클(cycle)을 가짐

* 교착 상태 발생 조건
    * 교착 상태 발생 조건에는 상호 배제, 점유와 대기, 비선점, 원형 대기가 있음
        * 네 가지 조건 중 하나라도 만족하지 않는다면 교착 상태가 발생하지 않음
        * 모두 만족될 때 교착 상태가 발생할 가능성이 생김
        1. 상호 배제 : 한 프로세스가 사용하는 자원을 다른 프로세스가 사용할 수 없음
        2. 점유와 대기 : 자원을 할당받은 상태에서 다른 자원을 할당받기를 기다리는 상태
        3. 비선점 : 프로세스가 이용 중인 자원을 강제로 빼앗지 못함
        4. 원형 대기 : 프로세스들이 (자원 할당 그래프에서) 원의 형태로 자원을 대기하는 것


### 교착 상태 해결 방법
* 교착 상태 예방
    * 교착 상태 발생 필요 조건 네 가지 중 하나를 충족하지 못하게 하는 방법
    * 교착 상태의 발생 조건을 원천적으로 제거하여 교착 상태를 사전에 방지 -> 교착 상태가 발생하지 않음을 보장할 수 있지만 여러 부작용이 따름
* 교착 상태 회피
    * 시스템이 안전 상태를 유지할 수 있는 경우에만 자원을 할당하는 방식
        * 안전 상태 : 안전 순서열이 존재하는 상태, (모든 프로세스가 최대로 자원을 요구한 최악의 상황에서도) 교착 상태가 발생하지 않고 모든 프로세스가 정상적으로 자원을 할당받고 종료될 수 있는 상태
        * 불안전 상태 : 안전 순서열이 존재하지 않는 상태, 교착 상태가 발생할 위험이 있음
        * 안전 순서열 : (최악의 상황에서도) 교착 상태 없이 안전하게 프로세스들에 자원을 할당할 수 있는 순서
    * 참고 : 프로세스와 스레드는 자원을 사용하기 위해 우선 자원을 운영체제에 요청하고, 운영체제로부터 자원을 할당받고, 자원의 사용이 끝났다면 자원을 반환함
* 교착 상태 검출 후 회복
    * 교착 상태 발생을 인정하고 사후에 조치하는 방식
    * 교착 상태 예방과 회피는 교착 상태 발생을 막는 방식
    * 검출 후 회복 방식에서 운영체제는 프로세스들이 자원을 요구할 때마다 그때그때 모두 할당하며, 교착 상태 발생 여부를 주기적으로 검사 -> 교착 상태가 검출되면 그때 비로소 다음과 같은 방식으로 회복
        * 선점을 통한 회복 : 교착 상태가 해결될 때까지 다른 프로세스로부터 자원을 강제로 빼앗아 한 프로세스씩 자원을 몰아주는 방식
        * 프로세스 강제 종료를 통한 회복
            * 가장 단순하면서 확실한 방식
            * 교착 상태에 놓인 프로세스를 모두 강제 종료하거나, 교착 상태가 없어질 때까지 한 프로세스씩 강제 종료
                * 전자는 한 번에 교착 상태를 해결 가능하지만, 그만큼 많은 프로세스들이 작업 내역을 잃게 될 가능성이 있음
                * 후자는 작업 내역을 잃는 프로세스는 최대한 줄일 수 있지만 교착 상태가 없어졌는지 여부를 확인하는 과정에서 오버헤드 발생
* 교착 상태를 아예 무시하는 방법도 있음
    * 타조 알고리즘 : 드물게 발생하는 잠재적 문제를 무시로 대처하는 방식
    * 이 방식이 적합한 경우도 있음


## 메모리 관리 기법
### 연속 메모리 할당
* 연속 메모리 할당 : 프로세스에 연속적인 메모리 공간을 할당하는 방식
* 스와핑 : 메모리에서 사용되지 않는 일부 프로세스를 보조기억장치의 스왑 영역으로 내보내고 실행할 프로세스를 메모리로 들여오는 메모리 관리 기법
    * 스왑 영역 : 내보낸 프로세스를 적재하는 보조기억장치의 일부 영역
    * 스왑 아웃 : 현재 실행되지 않는 프로세스가 메모리에서 스왑 영역으로 옮겨지는 것
    * 스왑 인 : 스왑 영역에 있던 프로세스가 다시 메모리로 옮겨오는 것
* 연속 메모리 할당 방식
    1. 최초 적합
        * 최초로 발견한 적재 가능한 빈 공간에 프로세스를 배치하는 방식
        * 검색을 최소화할 수 있고 빠른 할당이 가능
    2. 최적 적합
        * 프로세스가 적재될 수 있는 가장 작은 공간에 프로세스를 배치하는 방식
    3. 최악 적합
        * 프로세스가 적재될 수 있는 가장 큰 공간에 프로세스를 배치하는 방식
* 외부 단편화 : 프로세스를 할당하기 어려울 만큼 작은 메모리 공간들로 인해 메모리가 낭비되는 현상
    * 해결 방법
        * 압축(메모리 조각 모음) : 메모리 내에 저장된 프로세스를 적당히 재배치시켜 여기저기 흩어져 있는 작은 빈 공간들을 하나의 큰 빈 공간으로 만드는 방법
            * 압축 작업 동안 시스템은 하던 일을 중지해야 함
            * 메모리의 데이터를 옮기는 작업은 많은 오버헤드 야기
            * 오버헤드를 최소화하는 압축 방법이 명확하지 않음
        * 페이징 기법


### 페이징을 통한 가상 메모리 관리
* 가상 메모리 : 실행하고자 하는 프로그램을 일부만 메모리에 적재하여 실제 물리 메모리보다 더 큰 프로세스를 실행할 수 있게 하는 기술
    * 가상 메모리 관리 기법에는 페이징과 세그멘테이션이 있음
* 페이징 : 메모리의 물리 주소 공간을 프레임 단위로 자르고, 프로세스의 논리 주소 공간을 페이지 단위로 자른 뒤 각 페이지를 프레임에 할당하는 가상 메모리 관리 기법
    * 페이징에서도 스와핑을 사용할 수 있음
        * 페이지 단위로 스왑 아웃/스왑 인
            * 페이지 아웃/페이지 인으로 부르기도 함
        * 프로세스를 이루는 페이지 중 실행에 필요한 일부 페이지만 메모리에 적재하고, 당장 실행에 필요하지 않은 페이지들은 보조기억장치에 남겨둠 -> 물리 메모리보다 더 큰 프로세스도 실행 가능
    * 내부 단편화
        * 페이징에서 프로세스의 논리 주소 공간을 페이지라는 일정한 크기 단위로 자를 때 마지막 페이지에서 메모리가 낭비되는 것
        * 내부 단편화는 하나의 페이지 크기보다 작은 크기로 발생하므로 페이지 크기가 작다면 발생하는 내부 단편화의 크기도 작아짐
        * 그러나 페이지 크기를 너무 작게 설정하면 그만큼 페이지 테이블의 크기도 커지므로 페이지 테이블이 차지하는 공간이 너무 커짐
        * 내부 단편화를 적당히 방지하면서 페이지 테이블이 너무 커지지 않도록 페이지 크기를 조정하는 것이 중요
* 페이지 테이블
    * 프로세스의 페이지 번호와 해당 페이지가 할당된 프레임 번호를 짝지은 표
    * CPU는 페이지 테이블을 이용하여 페이지가 적재된 프레임을 알 수 있음
    * 각 프로세스의 페이지 테이블들은 메모리에 적재되어 있음
    * 페이지 테이블 베이스 레지스터(PRBR; Page Table Base Register) : 각 프로세스의 페이지 테이블이 적재된 주소를 저장하는 레지스터
    * 페이지 테이블을 메모리에 두면 메모리 접근 시간이 두 배로 늘어남
        * 페이지 테이블에 접근 + 프레임에 접근
        * 이를 해결하기 위해 CPU 곁에(일반적으로 MMU 내에) TLB(Translation Lookaside Buffer)라는 페이지 테이블의 캐시 메모리를 둠
            * TLB에는 페이지 테이블의 일부 내용 저장 (참조 지역성에 근거해 최근에 사용된 페이지 위주로 가져와 저장)
            * TLB 히트 : CPU가 접근하려는 논리 주소에 대한 페이지 번호가 TLB에 있는 경우
                * 페이지 테이블에 접근할 필요 없으므로 메모리 접근이 한 번으로 감소
            * TLB 미스 : CPU가 접근하려는 논리 주소에 대한 페이지 번호가 TLB에 없는 경우
                * 페이지 테이블에 접근해야 함
* 페이징에서의 주소 변환
    * 페이징 시스템에서는 모든 논리 주소가 기본적으로 페이지 번호와 변위로 이루어짐
    * 논리 주소 <페이지 번호, 변위>는 페이지 테이블을 통해 물리 주소 <프레임 번호, 변위>로 변환됨
* 페이지 테이블 엔트리
    * 페이지 테이블의 각각의 행
    * 페이지 번호, 프레임 번호 이외에도 다른 중요한 정보들이 담김
        1. 유효 비트 : 현재 해당 페이지가 메모리에 적재되어 있는지 여부를 나타내는 비트
            * 페이징에서도 스와핑을 사용할 수 있으므로 프로세스를 이루는 모든 페이지가 메모리에 있지 않을 수 있음
            * CPU가 유효 비트가 0인 페이지에 접근하려고 하면 페이지 폴트라는 예외가 발생
                * CPU는 다음과 같이 페이지 폴트를 처리
                    1. CPU는 기존의 작업 내역을 백업
                    2. 페이지 폴트 처리 루틴을 실행
                    3. 페이지 폴트 처리 루틴은 원하는 페이지를 메모리로 가져온 뒤 유효 비트를 1로 변경
                    4. 기존 작업으로 돌아와 CPU는 해당 페이지에 접근 (예외를 발생시킨 명령어 다시 실행)
        2. 보호 비트 : 페이지에 접근할 권한을 제한하여 페이지를 보호하는 비트
            * 읽기/쓰기/실행 가능한 페이지인지 여부를 나타냄
            * 읽기 전용 페이지에 쓰기를 시도하면 운영체제가 막아주는 방식으로 페이지를 보호 
        3. 참조 비트 : CPU가 페이지에 접근한 적이 있는지 여부를 나타내는 비트
            * 적재 이후 CPU가 읽거나 쓴 페이지는 참조 비트가 1로 설정되고, 적재 이후 한 번도 읽거나 쓴 적이 없는 페이지는 0으로 유지됨
        4. 수정 비트 : 해당 페이지에 데이터를 쓴 적이 있는지 여부(수정 여부)를 나타내는 비트
            * 더티 비트라고도 부름
            * 수정 비트가 1이면 변경된 적이 있는 페이지, 0이면 변경된 적이 없는 페이지(한 번도 접근한 적 없거나 읽기만 했던 페이지)임을 나타냄
            * 페이지가 메모리에서 스왑 아웃될 때 보조기억장치에 쓰기 작업을 해야 하는지 판단하기 위해 존재
* 페이징의 이점 - 쓰기 시 복사(copy on write)
    * 유닉스나 리눅스와 같은 운영체제에서 fork 시스템 호출 시 부모 프로세스의 복사본이 자식 프로세스로서 만들어짐
        * 부모 프로세스의 메모리 영역이 다른 영역에 자식 프로세스로서 복제되고, 각 프로세스의 페이지 테이블은 자신의 고유한 페이지가 할당된 프레임을 가리킴
        * 이 복사 작업은 프로세스 생성 시간을 늦출 뿐만 아니라 불필요한 메모리 낭비를 야기함
    * 쓰기 시 복사에서는 fork 시스템 호출 시 자식 프로세스의 코드 및 데이터 영역에 해당하는 페이지는 부모 프로세스의 코드 및 데이터 영역에 해당하는 프레임을 가리킴
        * 부모 프로세스와 자식 프로세스가 메모리에 이 영역에 어떠한 데이터도 쓰지 않고 읽기 작업만 한다면 이 상태가 지속
        * 둘 중 하나가 페이지에 쓰기 작업을 하면 해당 페이지가 별도의 공간으로 복제되고, 각 프로세스는 자신의 고유한 페이지가 할당된 프레임을 가리킴 -> 쓰기 시 복사
        * 쓰기 시 복사를 통해 프로세스 생성 시간을 줄이는 것은 물론 메모리 공간 절약도 가능함
* 계층적 페이징
    * 프로세스의 크기가 커지면 페이지 테이블의 크기도 커지므로 모든 페이지 테이블 엔트리를 메모리에 두는 것은 메모리 낭비임
    * 모든 페이지 테이블 엔트리를 항상 메모리에 유지하지 않을 수 있는 방법 -> 계층적 페이징
    * 계층적 페이징 : 페이지 테이블을 페이징하여 여러 단계의 페이지를 두는 방식
        * 다단계 페이지 테이블 기법이라고도 부름
        * 페이지 테이블을 여러 개의 페이지로 자르고, 바깥쪽에 페이지 테이블을 하나 더 두어 페이지 테이블의 잘린 페이지들을 가리키게 하는 방식
            * 가장 바깥쪽 페이지 테이블만 메모리에 유지하면 되고, 나머지 페이지 테이블들은 보조기억장치에 두었다가 추후 참조가 필요한 경우 메모리에 적재하면 됨 -> 메모리 낭비 완화
        * 계층적 페이징을 사용하는 경우 CPU가 발생시키는 논리 주소도 달라짐
            * <페이지 번호, 변위> -> <바깥 페이지 번호, 안쪽 페이지 번호, 변위>
        * 페이지 테이블의 계층이 늘어날수록 TLB 미스가 발생했을 경우 메모리 접근 횟수가 많아지므로 계층이 많다고 해서 반드시 좋은 것은 아님


### 페이지 교체와 프레임 할당
* 요구 페이징 : 프로세스를 메모리에 적재할 때 처음부터 모든 페이지를 적재하지 않고 페이지가 필요할 때에만 메모리에 적재하는 기법
    * 페이지가 필요할 때 : 페이지 폴트가 발생하는 경우
    * 순수 요구 페이징 : 아무런 페이지도 메모리에 적재하지 않은 채 무작정 실행하는 요구 페이징 기법
    * 요구 페이징 시스템이 안정적으로 동작하려면 페이지 교체와 프레임 할당을 해결해야 함
* 페이지 교체 알고리즘
    * 요구 페이징 기법으로 페이지들을 적재하다 보면 메모리가 가득 차게 되므로 당장 실행에 필요한 페이지들을 적재하기 위해 메모리에 적재된 페이지를 보조기억장치로 내보내야 함
        * 내보낼 페이지를 결정하는 방법 -> 페이지 교체 알고리즘
    * 좋은 페이지 교체 알고리즘은 페이지 폴트를 적게 일으키는 알고리즘
    * 종류
        1. FIFO 페이지 교체 알고리즘
            * 가장 단순한 방법으로, 메모리에 가장 먼저 적재된 페이지부터 교체하는 알고리즘
            * 실행 초기에 적재된 페이지 중에는 프로그램 실행 내내 사용될 내용을 포함하는 것도 있을 수 있으므로 좋은 방법이 아님
            * 2차 기회 페이지 교체 알고리즘
                * FIFO 페이지 교체 알고리즘의 부작용을 개선한 변형 알고리즘
                * 가장 오래 적재되었던 페이지의 참조 비트가 1인 경우 내보내지 않고 참조 비트를 0으로 만든 뒤 현재 시각을 적재 시각으로 설정 -> second chance
                    * 가장 오래된 페이지의 참조 비트가 0이면 보조기억장치로 내보냄
        2. 최적 페이지 교체 알고리즘
            * 앞으로 가장 오랫동안 사용되지 않을 페이지를 교체하는 알고리즘
            * 가장 낮은 페이지 폴트율을 보장하는 알고리즘
            * '앞으로 오랫동안 사용되지 않을 페이지'를 예측하는 것은 어려움 -> 구현이 현실적으로 불가
                * 실제로 운영체제에서 사용하기보다는 다른 페이지 교체 알고리즘의 성능을 평가하기 위한 기준(페이지 폴트율 하한선)으로 사용
        3. LRU 페이지 교체 알고리즘
            * Least Recently Used Page Replacement Algorithm
            * 최적 페이지 교체 알고리즘을 변형
                * 가장 오랫동안 사용되지 '않은' 페이지를 교체하는 알고리즘
            * '최근에 사용되지 않은 페이지는 앞으로도 사용되지 않을 것'이라는 아이디어를 토대로 만들어짐
* 스레싱과 프레임 할당
    * 사용 가능한 프레임 수가 적으면 페이지 폴트가 자주 발생함 (극단적 예시 : 사용 가능 프레임 수가 1인 경우)
        * 페이지 교체에 많은 시간을 쏟아야 하므로 CPU 이용률이 떨어지고 성능이 악화됨
    * 스레싱(thrashing) : 지나치게 빈번한 페이지 교체로 인해 CPU 이용률이 낮아지는 문제
        * 스레싱은 근본적으로 각 프로세스가 필요로 하는 최소한의 프레임 수가 보장되지 않아서 발생
        * 따라서 운영체제는 각 프로세스가 무리 없이 실행되기 위한 최소한의 프레임 수를 파악하고 프로세스들에 적절한 수만큼 프레임을 할당해야 함
    * 프레임 할당 방식
        * 정적 할당 방식
            * 균등 할당 : 모든 프로세스에 균등하게 프레임 할당
            * 비례 할당 : 프로세스 크기를 고려해 프레임 할당
            * 균등/비례 할당 방식은 프로세스의 실행 과정을 고려하지 않고 프로세스와 물리 메모리의 크기만 고려한 방식이라는 점에서 정적 할당 방식으로 분류
        * 동적 할당 방식
            * 하나의 프로세스가 실제로 얼마나 많은 프레임을 필요로 하는지는 실제로 실행해 봐야 알 수 있는 경우가 많음
            * 프로세스의 실행을 보고 할당할 프레임 수를 결정하는 방식
            * 작업 집합 모델(working set model) 기반 프레임 할당
                * 작업 집합 : 실행 중인 프로세스가 일정 시간 동안 참조한 페이지의 집합
                * 운영체제는 작업 집합의 크기만큼 프로세스에 프레임을 할당
            * 페이지 폴트 빈도(PFF; Page Fault Frequency) 기반 프레임 할당 (페이지 폴트율 기반 프레임 할당)
                * 개별 프로세스에 대한 페이지 폴트율은 해당 프로세스에 할당된 프레임 수와 반비례
                * 페이지 폴트율에 상한선과 하한선을 정해 페이지 폴트율이 상한선보다 높아지면 프레임을 더 할당하고, 하한선보다 낮아지면 프레임을 회수하여 다른 프로세스에 할당


## 파일 시스템
### 파일과 디렉터리
* 파일 : 보조기억장치에 저장된 관련 정보의 집합
    * 의미 있고 관련 있는 정보를 모은 논리적 단위
    * 파일 이름, 파일을 실행하기 위한 정보, 파일 관련 부가 정보(속성 또는 메타데이터)로 이루어짐
    * 파일 속성
        * 파일 유형 : 운영체제가 인식하는 파일 종류
            * 파일 유형에 따라 실행 방식이 달라짐
            * 운영체제는 파일의 확장자를 통해 파일 유형을 파악할 수 있음
    * 파일을 조작하는 모든 작업은 운영체제를 통해 이루어짐 -> 운영체제는 파일 연산을 위한 시스템 호출을 제공
* 디렉터리(폴더\[Window\]) : 파일들을 일목요연하게 관리하기 위한 (특별한 형태의) 파일
    * 루트 디렉터리 : 최상위 디렉터리
    * 경로 : 디렉터리를 이용해 위치를 특정 짓는 정보
        * 절대 경로 : 루트 디렉터리부터 시작하는 경로
            * 모든 파일은 고유한 절대 경로를 가짐
        * 상대 경로 : 현재 디렉터리부터 시작하는 경로
    * 운영체제는 디렉터리 연산을 위한 시스템 호출도 제공
    * 디렉터리는 내부에 해당 디렉터리에 담겨 있는 대상(파일과 디렉터리)과 관련된 정보를 담고 있음
    * 디렉터리는 보조기억장치에 테이블 형태의 정보로 저장됨
        * 파일 시스템에 무관하게 디렉터리 엔트리는 디렉터리에 포함된 대상의 '이름'과 그 대상이 '보조기억장치 내에 저장된 위치를 유추할 수 있는 정보'를 공통으로 포함
        * FAT 파일 시스템은 디렉터리 엔트리에 파일 속성을 명시


### 파일 시스템
* 파일 시스템 : 파일과 디렉터리를 관리하는 운영체제 내부 프로그램
* 파티셔닝 : 하드 디스크나 SSD처럼 용량이 큰 저장 장치를 하나 이상의 논리적인 단위로 구획하는 작업
    * 나누어진 영역 각각을 파티션이라고 함
* 포매팅 : 파일 시스템을 설정하고 새로운 데이터를 쓸 수 있도록 준비하는 작업
    * 파티션마다 다른 파일 시스템을 설정할 수도 있음
* 파일 할당 방법 (하드 디스크의 경우)
    * 운영체제는 파일과 디렉터리를 블록 단위로 읽고 씀
        * 하드 디스크의 가장 작은 단위는 섹터이지만, 개수가 너무 많고 크기도 작으므로 운영체제는 하나 이상의 섹터를 블록이라는 단위로 묶은 뒤 블록 단위로 파일과 디렉터리를 관리함
    * 연속 할당 : 보조기억장치 내 연속적인 블록에 파일을 할당하는 방식
        * 디렉터리 엔트리에 파일 이름, 첫 번째 블록 주소, 블록 단위의 길이를 명시
        * 구현이 단순하지만 외부 단편화 야기
    * 불연속 할당
        * 연결 할당 : 각 블록 일부에 다음 블록의 주소를 저장하여 블록들을 연결 리스트 형태로 관리하는 방식
            * 디렉터리 엔트리에 파일 이름, 첫 번째 블록 주소, 블록 단위의 길이 명시
            * 외부 단편화 문제를 해결하지만 임의 접근(random access) 속도가 느리고 하드웨어 고장이나 오류 발생 시 해당 블록 이후 블록은 접근 불가
        * 색인 할당
            * 파일의 모든 블록 주소를 색인 블록에 모아 관리하는 방식
            * 연결 할당과 달리 임의 접근 속도가 빠름
            * 디렉터리 엔트리에 파일 이름, 색인 블록 주소를 명시
* FAT 파일 시스템
    * FAT를 이용하는 연결 할당 기반의 파일 시스템
        * 임의 접근이 느리고, 하드웨어 고장/오류에 취약한 근본적인 원인은 블록 안에 다음 블록의 주소를 저장했기 때문 -> FAT를 이용하여 이러한 단점들을 상당 부분 해소함
        * 파일 할당 테이블(FAT; File Allocation Table) : 각 블록에 포함된 다음 블록의 주소들을 한데 모아 테이블 형태로 관리
        * 디렉터리 엔트리에는 파일 이름, 첫 번째 블록 주소 명시
    * USB, SD 카드와 같은 저용량 저장 장치용 파일 시스템으로 많이 이용
    * FAT 파일 시스템을 사용하는 파티션은 예약 영역, FAT 영역, 루트 디렉터리 영역, 데이터 영역으로 구성
        * 데이터 영역에는 서브 디렉터리와 파일들이 저장됨
        * FAT는 (파일 시스템) 실행 도중 메모리에 캐시될 수 있음
            * FAT가 메모리에 적재된 채 실행되면 임의 접근 성능이 개선됨
    * FAT 파일 시스템의 디렉터리 엔트리에는 파일 이름, 파일의 첫 번째 블록 주소 이외에도 파일 속성과 관련된 다양한 정보들이 저장됨
* 유닉스 파일 시스템
    * i-node를 이용하는 색인 할당 기반의 파일 시스템
    * 유닉스 파일 시스템에서는 색인 블록을 i-node(index-node)라고 부름
        * i-node에는 파일 속성 정보와 열다섯 개의 블록 주소가 저장될 수 있음
        * 파일마다 i-node가 있고, i-node마다 번호가 부여됨
    * 유닉스 파일 시스템을 사용하는 파티션은 예약 영역, i-node 영역, 데이터 영역으로 구성
        * i-node 영역에는 i-node들이 저장됨
        * 데이터 영역에는 디렉터리와 파일들이 저장됨
    * i-node가 파일의 데이터 블록들을 가리키는 방법
        1. 블록 주소 중 열두 개에는 직접 블록 주소를 저장함
            * 직접 블록 : 파일 데이터가 저장된 블록
        2. 1번 내용으로 충분하지 않다면 열세 번째 주소에 단일 간접 블록 주소를 저장함
            * 단일 간접 블록 : 직접 블록들의 주소가 저장된 블록
        3. 2번 내용으로 충분하지 않다면 열네 번째 주소에 이중 간접 블록 주소를 저장함
            * 이중 간접 블록 : 단일 간접 블록들의 주소가 저장된 블록
        4. 3번 내용으로 충분하지 않다면 열다섯 번째 주소에 삼중 간접 블록 주소를 저장함
            * 삼중 간접 블록 : 이중 간접 블록들의 주소가 저장된 블록
    * 유닉스 파일 시스템의 디렉터리 엔트리는 파일 이름과 i-node 번호로 구성
    * 유닉스 파일 시스템은 루트 디렉터리의 i-node를 항상 기억하고 있음
* 저널링 파일 시스템
    * 저널링 기법을 이용하는 파일 시스템
        * 저널링 기법 : 작업 로그를 통해 시스템 크래시가 발생했을 때 파일 시스템을 빠르게 복구하는 방법
            * 시스템 크래시 : 작업 도중 갑자기 전원이 나가거나 치명적인 오류로 인해 컴퓨터가 강제로 종료되는 것
        * 저널링 기법을 사용하는 파일 시스템에서 파일 시스템을 변경하는 작업은 다음과 같은 순서로 수행됨
            1. 작업 직전 파티션의 로그 영역에 수행하는 작업(변경 사항)에 대한 로그를 남김
            2. 작업 수행
            3. 로그 삭제
        * 작업 도중 시스템 크래시가 발생하여 다시 부팅을 해야 된다면 시스템 전체를 검사할 필요 없이 로그 영역에 남긴 로그만 검사하면 됨
            * 저널링 파일 시스템은 시스템 크래시 발생 직후 로그 영역을 읽어 크래시 발생 당시 어떤 작업을 실행 중이었는지 알아낸 다음 해당 작업을 완료함
* 마운트 : 한 저장 장치의 파일 시스템에서 다른 저장 장치의 파일 시스템에 접근할 수 있도록 파일 시스템을 편입시키는 작업